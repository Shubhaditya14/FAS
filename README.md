# Face Anti-Spoofing System (FAS)

ğŸ¥ Real-time face liveness detection using deep learning with FeatherNet architecture and ensemble support.

## ğŸš€ Quick Start

### Using the Launcher Script (Recommended)

```bash
./start.sh
```

This interactive menu provides access to all features.

### Direct Commands

```bash
# Activate environment
source venv/bin/activate

# Webcam live detection (Best!)
streamlit run app_webcam.py

# Image upload interface
streamlit run app.py

# Ensemble demo
streamlit run app_ensemble.py
```

---

## ğŸ¯ Features

- âœ… **Real-time Webcam Detection** - Live face liveness detection with overlay
- âœ… **Ensemble Support** - Combine multiple models for better accuracy
- âœ… **Temporal Smoothing** - Reduce jitter in video predictions
- âœ… **Multiple Fusion Strategies** - Average, weighted, max, voting
- âœ… **Production-Ready API** - FASInference class for integration
- âœ… **Comprehensive Metrics** - APCER, BPCER, ACER, EER
- âœ… **Multi-Device Support** - MPS (Apple Silicon), CUDA, CPU
- âœ… **Interactive Web UI** - Streamlit applications with rich visualization

---

## ğŸ“± Available Applications

### 1. ğŸ¥ Webcam Live Detection
**Recommended for demos and real-time use**

```bash
streamlit run app_webcam.py
```

Features:
- Live video feed with prediction overlay
- FPS counter and performance metrics
- Start/Stop/Snapshot controls
- Prediction history tracking
- Configurable threshold and model selection

### 2. ğŸ“¸ Image Upload Interface

```bash
streamlit run app.py
```

Features:
- Upload images or use camera snapshot
- Detailed probability breakdown
- Multiple model selection
- Confidence visualization

### 3. ğŸ”€ Ensemble Demo

```bash
streamlit run app_ensemble.py
```

Features:
- Multi-model ensemble testing
- Fusion strategy comparison
- Individual model predictions
- Weight configuration

---

## ğŸ¬ Command-Line Inference

### Single Image

```bash
python inference.py --image test.jpg --device mps
```

### Video Processing

```bash
python inference.py --video input.mp4 --output result.mp4 --temporal-smoothing --device mps
```

### Webcam Real-Time

```bash
python inference.py --camera 0 --temporal-smoothing --display --device mps
```

### Ensemble Inference

```bash
python inference.py --image test.jpg --ensemble --fusion-type average --device mps
```

**Advanced Options:**
- `--threshold`: Detection threshold (0.0-1.0, default: 0.5)
- `--temporal-smoothing`: Enable video smoothing (default: on)
- `--smoothing-window`: Smoothing window size (default: 5)
- `--skip-frames`: Process every Nth frame for speed
- `--fusion-type`: average|weighted|max|voting

---

## ğŸ“Š Evaluation

```bash
# Evaluate all fusion strategies
python eval_ensemble.py \
    --real-dir siw/test/real \
    --spoof-dir siw/test/spoof \
    --fusion-type all \
    --device mps \
    --output-dir eval_results

# Single fusion strategy
python eval_ensemble.py \
    --real-dir Oulu-NPU/true \
    --spoof-dir Oulu-NPU/false \
    --fusion-type average \
    --device mps
```

---

## ğŸ“¦ Pretrained Models

Located in `pth/` directory:

| Model | Size | Classes | Use Case |
|-------|------|---------|----------|
| AntiSpoofing_bin_128.pth | 2.8 MB | 2 | General binary (Real/Spoof) |
| AntiSpoofing_print-replay_128.pth | 2.8 MB | 3 | Print & replay attacks |
| AntiSpoofing_print-replay_1.5_128.pth | 2.8 MB | 3 | Enhanced version |

**Model Specs:**
- Architecture: FeatherNet
- Parameters: 695K
- Input Size: 128x128
- Inference: ~40-50ms (MPS)

**Note:** Ensemble currently supports binary (2-class) models only.

---

## âš™ï¸ Configuration

### Device Selection

Automatically uses best available:
- **MPS** (Apple Silicon): 25-30 FPS
- **CUDA** (NVIDIA GPU): 30+ FPS  
- **CPU**: 10-15 FPS (fallback)

### Detection Threshold

Balance false positives vs false negatives:
- **0.3-0.4**: Lenient (fewer false rejections)
- **0.5**: Balanced (default)
- **0.6-0.7**: Strict (fewer false accepts)

### Fusion Strategies

- **Average**: Simple mean (baseline)
- **Weighted**: Custom per-model weights
- **Max**: Maximum confidence (conservative)
- **Voting**: Majority voting

---

## ğŸ“ Project Structure

```
FAS/
â”œâ”€â”€ app_webcam.py              # ğŸ¥ Live webcam UI (NEW!)
â”œâ”€â”€ app.py                     # ğŸ“¸ Image upload UI
â”œâ”€â”€ app_ensemble.py            # ğŸ”€ Ensemble demo UI
â”œâ”€â”€ inference.py               # ğŸ¬ CLI inference with temporal smoothing
â”œâ”€â”€ multi_model_predictor.py   # ğŸ¤– Ensemble predictor
â”œâ”€â”€ eval_ensemble.py           # ğŸ“Š Evaluation script
â”œâ”€â”€ start.sh                   # ğŸš€ Interactive launcher
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ feathernet.py          # FeatherNet architecture (695K params)
â”‚   â”œâ”€â”€ fusion/                # Fusion modules
â”‚   â””â”€â”€ backbones/             # Legacy backbones
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_loader.py         # Dataset utilities
â”‚   â”œâ”€â”€ metrics.py             # APCER, BPCER, ACER, EER
â”‚   â”œâ”€â”€ augmentations.py       # Data augmentation
â”‚   â””â”€â”€ preprocessing.py       # Image preprocessing
â”‚
â”œâ”€â”€ pth/                       # Pretrained models (2.8 MB each)
â”‚   â”œâ”€â”€ AntiSpoofing_bin_128.pth
â”‚   â”œâ”€â”€ AntiSpoofing_print-replay_128.pth
â”‚   â””â”€â”€ AntiSpoofing_print-replay_1.5_128.pth
â”‚
â””â”€â”€ configs/                   # YAML configurations
```

---

## ğŸ“ Usage Examples

### Example 1: Quick Demo

```bash
./start.sh
# Select option 1: Webcam Live Detection
# Click "Start Camera" in browser
```

### Example 2: Test Images

```bash
# Test real face
python inference.py --image siw/test/real/face1.jpg --device mps

# Test spoof
python inference.py --image siw/test/spoof/attack1.jpg --device mps
```

### Example 3: Ensemble Comparison

```bash
python eval_ensemble.py \
    --real-dir Oulu-NPU/true \
    --spoof-dir Oulu-NPU/false \
    --fusion-type all \
    --device mps
```

### Example 4: Video with Temporal Smoothing

```bash
python inference.py \
    --video input.mp4 \
    --output output.mp4 \
    --temporal-smoothing \
    --smoothing-window 7 \
    --device mps
```

---

## ğŸ”§ Requirements

- **Python:** 3.11 or 3.12 (3.13 has PyTorch issues)
- **RAM:** 4GB minimum, 8GB recommended
- **Storage:** 1GB for models
- **Optional:** Apple Silicon (MPS) or NVIDIA GPU (CUDA)

**Key Dependencies:**
- PyTorch 2.1+
- Streamlit
- OpenCV (cv2)
- Albumentations
- Pillow

```bash
pip install -r requirements.txt
```

---

## ğŸ› Troubleshooting

### Camera Not Working

```bash
# Try different camera index
python inference.py --camera 1

# Check available cameras (macOS)
system_profiler SPCameraDataType
```

### Slow Performance

```bash
# Use hardware acceleration
python inference.py --image test.jpg --device mps  # or cuda

# Skip frames in video
python inference.py --video input.mp4 --skip-frames 2
```

### Model Not Found

```bash
# List available models
ls -lh pth/

# Verify model loads
python -c "from models.feathernet import create_feathernet; print('OK')"
```

---

## ğŸ“– Documentation

- **ENSEMBLE_SUMMARY.md** - Ensemble implementation (Steps 1-2)
- **STEP5_INFERENCE_SUMMARY.md** - Inference API details (Step 5)
- **STEP7_WEBCAM_SUMMARY.md** - Webcam app documentation (Step 7)
- **PROJECT_STATE.md** - Overall project status
- **plan.md** - Implementation roadmap

---

## ğŸ¯ Performance Benchmarks

### Single Model (FeatherNet)
- **MPS:** ~45ms, 25-30 FPS, 200MB RAM
- **CUDA:** ~35ms, 30+ FPS, 250MB RAM
- **CPU:** ~100ms, 10-15 FPS, 250MB RAM

### Ensemble (3 Models, Average Fusion)
- **MPS:** ~150ms, 20-25 FPS, 400MB RAM
- **CPU:** ~300ms, 5-10 FPS, 500MB RAM

---

## ğŸš§ Project Status

**MVP COMPLETE! âœ…**

Completed:
- âœ… Step 1: Ensemble Architecture
- âœ… Step 5: Inference API Refinement  
- âœ… Step 7: Streamlit Webcam UI

Remaining (Optional):
- â³ Step 2: Domain Adaptation
- â³ Step 3: Training Pipeline
- â³ Step 4: Full Evaluation
- â³ Step 6: Model Export

**Current Capabilities:**
- Real-time webcam detection
- Ensemble support (4 fusion strategies)
- Temporal smoothing
- Production-ready inference API
- Interactive web UIs
- Comprehensive evaluation tools

---

## ğŸ¤ Contributing

For production deployment, consider:
1. Add face detection preprocessing
2. Support 3-class models in ensemble
3. Add attention map visualization
4. Deploy with FastAPI backend
5. Create mobile applications

---

## ğŸ™ Acknowledgments

- **FeatherNet:** Lightweight face anti-spoofing architecture
- **Pretrained Models:** For demonstration and research
- **Datasets:** OULU-NPU, SIW for evaluation

---

**Built with â¤ï¸ using PyTorch and Streamlit**

For detailed technical documentation, see the individual SUMMARY.md files.
