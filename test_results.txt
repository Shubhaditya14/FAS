========================================
FAS SYSTEM TEST RESULTS
========================================
Date: $(date)
========================================


========================================
TEST 1: MODEL ARCHITECTURE
========================================
Using device: mps
==================================================
TEST 1: Model Architecture
==================================================
✓ Model initialized
✓ Total parameters: 695,971
✓ Forward pass successful
  Input shape: torch.Size([2, 3, 128, 128])
  Output shape: torch.Size([2, 1])
  Output value: 0.5000
✓ Feature extraction works
  Feature shape: torch.Size([2, 128])


========================================
TEST 2: PRETRAINED WEIGHT LOADING
========================================
Using device: mps
==================================================
TEST 2: Pretrained Weight Loading
==================================================

Loading binary model (num_classes=2):
Loaded model from pth/AntiSpoofing_bin_128.pth
Model type: binary, Device: mps
  ✓ Loaded successfully
  ✓ Training mode: False
  ✓ Inference works, output: 0.0008

Loading multiclass model (num_classes=3):
Loaded model from pth/AntiSpoofing_print-replay_128.pth
Model type: binary, Device: mps
  ✓ Loaded successfully
  ✓ Training mode: False
  ✓ Inference works, output: 0.0000


========================================
TEST 3: PREPROCESSING PIPELINE
========================================
==================================================
TEST 3: Preprocessing Pipeline
==================================================

Testing with image: Oulu-NPU/true/1_2_47_1_1.jpg
✓ Preprocessing from path works
  Output shape: torch.Size([3, 128, 128])
  Output dtype: torch.float32
  Value range: [-2.118, 2.640]
✓ Preprocessing from numpy works
  Output shape: torch.Size([3, 128, 128])
✓ Batch preprocessing works
  Batch shape: torch.Size([2, 3, 128, 128])


========================================
TEST 4: DATASET LOADING
========================================
==================================================
TEST 4: Dataset Loading
==================================================

[OULU Dataset]
OULU train: 1190 samples
✓ OULU train dataset created
  Total samples: 1190
  Class distribution: {'real': 230, 'spoof': 960}
✓ Sample loaded
  Image shape: torch.Size([3, 128, 128])
  Label: 1 (spoof)
✓ DataLoader works
  Batch shape: torch.Size([16, 3, 128, 128])
  Batch labels: tensor([1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1])

[SIW Dataset]
SIW train: 6086 samples
✓ SIW train dataset created
  Total samples: 6086
  Class distribution: {'real': 4876, 'spoof': 1210}
✓ Sample loaded
  Image shape: torch.Size([3, 128, 128])
  Label: 0


========================================
TEST 5: SINGLE IMAGE INFERENCE
========================================
==================================================
TEST 5: Single Image Inference
==================================================
Loaded model from pth/AntiSpoofing_bin_128.pth
Model type: binary, Device: cpu
✓ Predictor initialized

[Real Image Test]
✓ Prediction successful
  Image: Oulu-NPU/true/1_2_47_1_1.jpg
  Prediction: REAL
  Confidence: 0.0000

[Spoof Image Test]
✓ Prediction successful
  Image: Oulu-NPU/false/1_3_48_3_1.jpg
  Prediction: REAL
  Confidence: 0.0207

[Batch Prediction Test]
✓ Batch prediction successful
  Image 1: REAL (conf: 0.0000)
  Image 2: REAL (conf: 0.0207)
  Image 3: REAL (conf: 0.0000)


========================================
TEST 6: FULL DATASET EVALUATION
========================================
==================================================
TEST 6: Full Dataset Evaluation
==================================================
Loaded model from pth/AntiSpoofing_bin_128.pth
Model type: binary, Device: cpu
✓ Model loaded

[OULU Test Set Evaluation]
OULU test: 256 samples
  Test samples: 256
Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]Evaluating:  12%|█▎        | 1/8 [00:00<00:04,  1.40it/s]Evaluating:  25%|██▌       | 2/8 [00:01<00:04,  1.44it/s]Evaluating:  38%|███▊      | 3/8 [00:02<00:03,  1.49it/s]Evaluating:  50%|█████     | 4/8 [00:02<00:02,  1.52it/s]Evaluating:  62%|██████▎   | 5/8 [00:03<00:01,  1.54it/s]Evaluating:  75%|███████▌  | 6/8 [00:03<00:01,  1.54it/s]Evaluating:  88%|████████▊ | 7/8 [00:04<00:00,  1.54it/s]Evaluating: 100%|██████████| 8/8 [00:05<00:00,  1.54it/s]Evaluating: 100%|██████████| 8/8 [00:05<00:00,  1.52it/s]

  Results:
    Accuracy:  0.6523
    Precision: 0.7906
    Recall:    0.7550
    F1:        0.7724
    AUC:       0.5202
    APCER:     0.2450
    BPCER:     0.7143
    ACER:      0.4796
    EER:       0.4736

[SIW Test Set Evaluation]
SIW test: 750 samples
  Test samples: 750
Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]Evaluating:   4%|▍         | 1/24 [00:00<00:11,  1.98it/s]Evaluating:   8%|▊         | 2/24 [00:00<00:10,  2.02it/s]Evaluating:  12%|█▎        | 3/24 [00:01<00:10,  2.04it/s]Evaluating:  17%|█▋        | 4/24 [00:01<00:09,  2.03it/s]Evaluating:  21%|██        | 5/24 [00:02<00:09,  2.03it/s]Evaluating:  25%|██▌       | 6/24 [00:02<00:08,  2.08it/s]Evaluating:  29%|██▉       | 7/24 [00:03<00:08,  2.12it/s]Evaluating:  33%|███▎      | 8/24 [00:03<00:07,  2.15it/s]Evaluating:  38%|███▊      | 9/24 [00:04<00:07,  2.13it/s]Evaluating:  42%|████▏     | 10/24 [00:04<00:06,  2.15it/s]Evaluating:  46%|████▌     | 11/24 [00:05<00:05,  2.17it/s]Evaluating:  50%|█████     | 12/24 [00:05<00:05,  2.18it/s]Evaluating:  54%|█████▍    | 13/24 [00:06<00:05,  2.20it/s]Evaluating:  58%|█████▊    | 14/24 [00:06<00:04,  2.20it/s]Evaluating:  62%|██████▎   | 15/24 [00:07<00:04,  2.21it/s]Evaluating:  67%|██████▋   | 16/24 [00:07<00:03,  2.21it/s]Evaluating:  71%|███████   | 17/24 [00:07<00:03,  2.21it/s]Evaluating:  75%|███████▌  | 18/24 [00:08<00:02,  2.19it/s]Evaluating:  79%|███████▉  | 19/24 [00:08<00:02,  2.18it/s]Evaluating:  83%|████████▎ | 20/24 [00:09<00:01,  2.18it/s]Evaluating:  88%|████████▊ | 21/24 [00:09<00:01,  2.18it/s]Evaluating:  92%|█████████▏| 22/24 [00:10<00:00,  2.18it/s]Evaluating:  96%|█████████▌| 23/24 [00:10<00:00,  2.18it/s]Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.76it/s]Evaluating: 100%|██████████| 24/24 [00:10<00:00,  2.22it/s]

  Results:
    Accuracy:  0.2027
    ACER:      0.5008
    AUC:       0.4774


========================================
ALL TESTS COMPLETED
========================================
